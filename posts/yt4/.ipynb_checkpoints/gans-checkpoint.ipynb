{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4039ff95-fbe1-44f5-8819-2fdcfdc69ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|     Component     |  Version   |\n",
      "+-------------------+------------+\n",
      "|       Python      |   3.12.2   |\n",
      "+-------------------+------------+\n",
      "|      PyTorch      | 2.2.2+cpu  |\n",
      "+-------------------+------------+\n",
      "| PyTorch Lightning |   2.2.3    |\n",
      "+-------------------+------------+\n",
      "|    torchvision    | 0.17.2+cpu |\n",
      "+-------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "from utils import *\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS=int(os.cpu_count() / 2)\n",
    "versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d98c1-3602-4c77-9a07-1b3eb1da6c17",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "Generative Adversarial Networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework. \n",
    "This technique was introduced by Ian Goodfellow and his colleagues in 2014 and has since been an active topic of research with applications including in generative image models, video generation, and voice generation systems.\n",
    "\n",
    "GANs consist of two distinct models: a **generator** and a **discriminator**:\n",
    "\n",
    "<img src=\"gan_structure.png\" style=\"width:75%\">\n",
    "\n",
    "- **Generator**: This network learns to generate plausible data. The generated instances become negative training samples for the discriminator.\n",
    "- **Discriminator**: This network learns to distinguish between real and fake data from the generator. The discriminator penalizes the generator for producing implausible results.\n",
    "\n",
    "When training a GAN, the generator and discriminator are trained simultaneously:\n",
    "\n",
    "1. **Generator Learning**: The generator improves its ability to create fake data by continuously attempting to deceive the discriminator. It tries to minimize the following function:\n",
    "\n",
    "    $$ \\min_G \\log(1 - D(G(z))) $$\n",
    "\n",
    "   where $G(z)$ is the generator's output when given noise $z$, and $D$ is the discriminator's estimate of the probability that a sample came from the training data rather than the generator.\n",
    "\n",
    "2. **Discriminator Learning**: The discriminator improves its ability to distinguish real data from fake data produced by the generator. It tries to maximize the following function:\n",
    "\n",
    "    $$ \\max_D \\, \\left[\\log D(x) + \\log(1 - D(G(z)))\\right] $$\n",
    "\n",
    "   where $x$ is data from the true distribution.\n",
    "\n",
    "The training involves back-and-forth iterations where the discriminator guides the generator to produce more realistic outputs, and the generator forces the discriminator to become more skilled at distinguishing real data from fakes.\n",
    "\n",
    "For a more comprehensive overview of GANs, refer to the original paper or additional resources on generative models:\n",
    "\n",
    "> [Original GAN Paper by Ian Goodfellow et al., 2014](https://arxiv.org/abs/1406.2661)\n",
    ">\n",
    "> [Generative Models on OpenAI](https://openai.com/blog/generative-models/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed183f-788d-4b42-8236-5121e8dfde63",
   "metadata": {},
   "source": [
    "# PyTorch Lightning\n",
    "\n",
    "> PyTorch Lightning is a library built on top of PyTorch that abstracts complexity so that researchers and developers can build models faster and more efficiently. By structuring PyTorch code to be more modular and hardware-agnostic, Lightning enables scalability across different hardware setups without changing the model code.\n",
    ">\n",
    ">PyTorch Lightning is designed for high flexibility and even higher performance, making it a popular choice for both academic researchers and industry practitioners.\n",
    ">\n",
    ">For more detailed information on PyTorch Lightning, visit the official documentation:\n",
    "> \n",
    ">> [PyTorch Lightning Documentation](https://pytorch-lightning.readthedocs.io/en/latest/)\n",
    "\n",
    "<br>\n",
    "\n",
    "To install PyTorch Lightning using the `pip` package manager run\n",
    "```cmd\n",
    "pip install pytorch_lightning\n",
    "```\n",
    "at the command line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92dfdb-ed1f-4bc4-82c2-670ca30cbf87",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Dataset\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article images, designed as a more challenging replacement for the traditional MNIST dataset of handwritten digits. Each example in Fashion-MNIST is a 28x28 grayscale image, associated with a label from 10 classes. \n",
    "\n",
    "- **Number of Samples**: 70,000 (60,000 training and 10,000 test images)\n",
    "- **Image Size**: 28x28 pixels, grayscale\n",
    "- **Number of Classes**: 10\n",
    "\n",
    "Each class corresponds to a type of clothing:\n",
    "    \n",
    ">    0. T-shirt/top\n",
    ">    1. Trouser\n",
    ">    2. Pullover\n",
    ">    3. Dress\n",
    ">    4. Coat\n",
    ">    5. Sandal\n",
    ">    6. Shirt\n",
    ">    7. Sneaker\n",
    ">    8. Bag\n",
    ">    9. Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20d3960-b464-49e7-90b7-19730038d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "class FashionMNISTDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning Data Module for the FashionMNIST dataset.\n",
    "    Handles the loading, downloading, and transforming of data into train, validation, and test splits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir=\"./data\", batch_size=32, num_workers=4):\n",
    "        \"\"\"\n",
    "        Initializes the data module.\n",
    "        \n",
    "        Args:\n",
    "            data_dir (str): The directory to store/download the dataset.\n",
    "            batch_size (int): Number of samples in each batch.\n",
    "            num_workers (int): Number of subprocesses to use for data loading.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Define transformations that will be applied to each data sample\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "            transforms.Normalize((0.5,), (0.5,)),  # Normalize grayscale images\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Download the FashionMNIST dataset if not already available locally.\n",
    "        This method is only called from a single GPU.\n",
    "        \"\"\"\n",
    "        FashionMNIST(self.data_dir, train=True, download=True)\n",
    "        FashionMNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Set up the dataset for the 'fit' and 'test' stages.\n",
    "        \n",
    "        Args:\n",
    "            stage (str, optional): Stage for which the setup is being run. \n",
    "                                   If 'fit', set up for training and validation. \n",
    "                                   If 'test', set up for testing.\n",
    "        \"\"\"\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            fashion_full = FashionMNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            # Randomly split the dataset into training and validation data\n",
    "            self.fashion_train, self.fashion_val = random_split(fashion_full, [55000, 5000])\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.fashion_test = FashionMNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            DataLoader: DataLoader for the training data.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.fashion_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            DataLoader: DataLoader for the validation data.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.fashion_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            DataLoader: DataLoader for the test data.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.fashion_test, batch_size=self.batch_size, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51a3db4-33a6-44aa-a404-56ddd74cef0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a278b0-15b7-45e3-8eb6-f2d928ff1d49",
   "metadata": {},
   "source": [
    "## Generator Architecture\n",
    "\n",
    "> The **Generator** is designed to map latent space vectors to the data space. It consists of a series of layers that progressively upsample the input vector to a higher resolution, culminating in an image of the desired size.\n",
    "> \n",
    "> - **Input**: Receives a latent vector of dimensionality `latent_dim`.\n",
    "> - **Layers**:\n",
    ">   - A fully connected layer expands the latent vector into a 7x7x64 tensor.\n",
    ">   - Two transposed convolutional layers (also known as deconvolutional layers) further upsample the tensor to larger spatial dimensions (14x14 and 28x28).\n",
    ">   - The final convolutional layer reduces the depth to produce a single-channel image, typically representing a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a8f31e-9c5c-4091-a390-96f31235efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator class for a GAN, producing images from a latent space input.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim):\n",
    "        \"\"\"\n",
    "        Initializes the Generator model.\n",
    "        Args:\n",
    "            latent_dim (int): Dimensionality of the latent space vector.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(latent_dim, 7 * 7 * 64)\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2)\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2)\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the Generator.\n",
    "        Args:\n",
    "            x (Tensor): Latent space input tensor.\n",
    "        Returns:\n",
    "            Tensor: Generated image tensor of shape [1, 28, 28].\n",
    "        \"\"\"\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = x.view(-1, 64, 7, 7)\n",
    "        x = F.relu(self.ct1(x))\n",
    "        x = F.relu(self.ct2(x))\n",
    "        x = self.conv(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b96cb-7a8d-4cd5-a9e2-380daef0192c",
   "metadata": {},
   "source": [
    "## Discriminator Architecture\n",
    "\n",
    "> The **Discriminator** evaluates images, distinguishing between samples drawn from the training data and those generated by the generator. It is structured as a conventional convolutional neural network (CNN), which downsamples the input image to a scalar output that estimates the probability of the input being a real image.\n",
    "> \n",
    "> - **Input**: Receives an image (real or generated).\n",
    "> - **Layers**:\n",
    ">   - Two convolutional layers with kernel size 5 for feature extraction, each followed by max pooling for spatial reduction.\n",
    ">   - Dropout layer after the second convolutional layer to prevent overfitting.\n",
    ">   - Two fully connected layers to output a probability score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6cf6f5-9ea0-495a-a3fd-fd61fd66d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator class for a GAN, distinguishing generated images from real images.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the Discriminator model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the Discriminator.\n",
    "        Args:\n",
    "            x (Tensor): Input image tensor.\n",
    "        Returns:\n",
    "            Tensor: Probability tensor indicating the likelihood of the input being real.\n",
    "        \"\"\"\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)  # Flatten the output for the dense layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712f1f2e-b7d6-48de-b2bf-72f3be91c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A GAN class inheriting from PyTorch Lightning Module for generating and discriminating images.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=100, lr=0.0002):\n",
    "        \"\"\"\n",
    "        Initializes the GAN model.\n",
    "        Args:\n",
    "            latent_dim (int): Dimensionality of the latent space.\n",
    "            lr (float): Learning rate for the optimizer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        self.validation_z = torch.randn(6, self.hparams.latent_dim)  # Validation noise\n",
    "        self.generator_losses = []\n",
    "        self.discriminator_losses = []\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the generator to create images from noise.\n",
    "        Args:\n",
    "            z (Tensor): A batch of random noise vectors.\n",
    "        Returns:\n",
    "            Tensor: Generated images.\n",
    "        \"\"\"\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Computes the binary cross-entropy loss for adversarial training.\n",
    "        Args:\n",
    "            y_hat (Tensor): Predicted probabilities.\n",
    "            y (Tensor): True labels.\n",
    "        Returns:\n",
    "            Tensor: Loss value.\n",
    "        \"\"\"\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training logic for one epoch's step.\n",
    "        Args:\n",
    "            batch: The output of your DataLoader. A tuple (images, labels) in this case.\n",
    "            batch_idx (int): Integer displaying index of this batch.\n",
    "        Returns:\n",
    "            Dictionary: Training loss and log metrics.\n",
    "        \"\"\"\n",
    "        real_imgs, _ = batch\n",
    "        d_loss = self._train_discriminator(real_imgs)\n",
    "        g_loss = self._train_generator(real_imgs.size(0))\n",
    "        self.generator_losses.append(g_loss.item())\n",
    "        self.discriminator_losses.append(d_loss.item())\n",
    "        self.log_dict({'g_loss': g_loss, 'd_loss': d_loss})\n",
    "        return {'loss': d_loss, 'progress_bar': {'g_loss': g_loss, 'd_loss': d_loss}, 'log': {'g_loss': g_loss, 'd_loss': d_loss}}\n",
    "\n",
    "    def plot_learning_curves(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "        plt.plot(self.generator_losses, label=\"Generator Loss\")\n",
    "        plt.plot(self.discriminator_losses, label=\"Discriminator Loss\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def _train_generator(self, batch_size):\n",
    "        \"\"\"\n",
    "        Handles the training of the generator.\n",
    "        Args:\n",
    "            batch_size (int): The size of the batch.\n",
    "        Returns:\n",
    "            Tensor: Generator loss.\n",
    "        \"\"\"\n",
    "        z = self._generate_noise(batch_size)\n",
    "        fake_imgs = self(z)\n",
    "        y_hat = self.discriminator(fake_imgs)\n",
    "        y = torch.ones(y_hat.shape, device=self.device)\n",
    "        g_loss = self.adversarial_loss(y_hat, y)\n",
    "        self.manual_backward(g_loss)\n",
    "        self.optimizers()[0].step()\n",
    "        self.optimizers()[0].zero_grad()\n",
    "        return g_loss\n",
    "\n",
    "    def _train_discriminator(self, real_imgs):\n",
    "        \"\"\"\n",
    "        Handles the training of the discriminator.\n",
    "        Args:\n",
    "            real_imgs (Tensor): Real images from the dataset.\n",
    "        Returns:\n",
    "            Tensor: Discriminator loss.\n",
    "        \"\"\"\n",
    "        # Train with real images\n",
    "        y_hat_real = self.discriminator(real_imgs)\n",
    "        y_real = torch.ones(y_hat_real.shape, device=self.device)\n",
    "        real_loss = self.adversarial_loss(y_hat_real, y_real)\n",
    "\n",
    "        # Train with fake images\n",
    "        z = self._generate_noise(real_imgs.size(0))\n",
    "        fake_imgs = self(z).detach()\n",
    "        y_hat_fake = self.discriminator(fake_imgs)\n",
    "        y_fake = torch.zeros(y_hat_fake.shape, device=self.device)\n",
    "        fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n",
    "\n",
    "        # Average losses for the discriminator\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        self.manual_backward(d_loss)\n",
    "        self.optimizers()[1].step()\n",
    "        self.optimizers()[1].zero_grad()\n",
    "        return d_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "    # This is necessary if you have defined a validation dataloader\n",
    "        pass\n",
    "\n",
    "\n",
    "    def _generate_noise(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generates a tensor of random noise.\n",
    "        Args:\n",
    "            batch_size (int): The size of the batch.\n",
    "        Returns:\n",
    "            Tensor: A batch of random noise vectors.\n",
    "        \"\"\"\n",
    "        return torch.randn(batch_size, self.hparams.latent_dim, device=self.device)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Initializes and returns optimizers for generator and discriminator.\n",
    "        Returns:\n",
    "            List: List containing optimizers for generator and discriminator.\n",
    "        \"\"\"\n",
    "        lr = self.hparams.lr\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def plot_imgs(self):\n",
    "        \"\"\"\n",
    "        Plots generated images to visualize progress using matplotlib.\n",
    "        \"\"\"\n",
    "        z = self.validation_z.to(self.generator.lin1.weight.device)\n",
    "        with torch.no_grad():  # Ensures that gradients are not calculated in the forward pass\n",
    "            sample_imgs = self(z).detach().cpu()  # Detach and move to CPU to avoid RuntimeError\n",
    "    \n",
    "        print(f'Epoch: {self.current_epoch}')\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        for i in range(sample_imgs.size(0)):\n",
    "            ax = fig.add_subplot(2, 3, i+1)\n",
    "            ax.imshow(sample_imgs[i, 0, :, :], cmap='Greys_r')\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        A hook called at the end of every epoch.\n",
    "        \"\"\"\n",
    "        self.plot_imgs()\n",
    "        self.plot_learning_curves()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483500a-ef52-416c-8c57-52a24db8bce8",
   "metadata": {},
   "source": [
    "## Training Process\n",
    "\n",
    "> During training, the generator and discriminator contest with each other:\n",
    ">\n",
    "> 1. **Generator** aims to fool the discriminator by generating increasingly convincing images.\n",
    "> 2. **Discriminator** strives to accurately classify real and generated images.\n",
    ">\n",
    "> The system is trained using a minimax game strategy, optimizing both networks concurrently to improve their accuracy and robustness. This adversarial setup helps improve the generative quality of the images as the training progresses.\n",
    "\n",
    "The following code cell creates instances of the `FashionMNISTDataModule` and `GAN` classes and then trains the model on the training data, using the jupyter magic command `%%time` to track the time taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1ec39-9dbb-4e35-a30e-7c1bb42901ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 358 K \n",
      "1 | discriminator | Discriminator | 21.4 K\n",
      "------------------------------------------------\n",
      "379 K     Trainable params\n",
      "0         Non-trainable params\n",
      "379 K     Total params\n",
      "1.520     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "C:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a686faaca54dff9a5c6aea408d67c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dm = FashionMNISTDataModule()\n",
    "model = GAN()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    check_val_every_n_epoch=1,  # Ensures validation happens and might trigger related hooks\n",
    "    logger=True,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "print('\\nTraining Complete.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a508b85-2558-4e97-aad9-12aaf85c4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21254fbc-ee19-40d1-a28d-6755c28db876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5e048-896d-41e2-ba2c-12017ac72602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
