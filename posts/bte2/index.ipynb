{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "832c74cf",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"The Boltzmann Equation - 2. Probabilistic Preliminaries\"\n",
    "author: \"Daniel J Smith\"\n",
    "date: \"2024-02-13\"\n",
    "categories: [Mathematics, Probability Theory, Boltzmann Equation]\n",
    "title-block-banner: false\n",
    "image: 'preview.png'\n",
    "draft: false\n",
    "description:  \"Before we can discuss Information Theory and its consequences for the Boltzmann equation, we first need to make some definitions from probability theory.\"\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836ac16",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "1. [Probability Theory](#toc1_)    \n",
    "1.1. [Random Variables and Random Vectors](#toc1_1_)    \n",
    "1.1.1. [Definition 1.1.1 - Random Variables](#toc1_1_1_)    \n",
    "1.1.2. [Definition 1.1.2 - Continuous RVs](#toc1_1_2_)    \n",
    "1.1.3. [Definition 1.1.3 - Random Vectors](#toc1_1_3_)    \n",
    "1.2. [Expectation, Moments and Independence](#toc1_2_)    \n",
    "1.2.1. [Definition 1.2.1 - Expectation](#toc1_2_1_)    \n",
    "1.2.2. [Definition 1.2.2 - Conditional Probability](#toc1_2_2_)    \n",
    "1.2.3. [Definition 1.2.3 - Independence of RVs](#toc1_2_3_)    \n",
    "1.2.4. [Remark 1.2.4](#toc1_2_4_)    \n",
    "2. [References](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=true\n",
    "\tminLevel=1\n",
    "\tmaxLevel=5\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed7916",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Probability Theory](#toc0_)\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1. <a id='toc1_1_'></a>[Random Variables and Random Vectors](#toc0_)\n",
    "\n",
    "Throughout we fix a probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$\n",
    "and consider $\\mathbb{R}$ equipped with Lebesgue measure $\\lambda$ on\n",
    "the Borel $\\sigma$-algebra $\\mathcal{B}(\\mathbb{R}).$ The reader is assumed to have taken a first course on measure theory.\n",
    "\n",
    "Note that a probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$ is a measure space with unit total mass\n",
    "\n",
    "$$\\mathbb{P}(\\Omega)=1.$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c142988",
   "metadata": {},
   "source": [
    "### 1.1.1. <a id='toc1_1_1_'></a>[Definition 1.1.1 - Random Variables](#toc0_)\n",
    "\n",
    "A **random variable** $X$ is a measurable function\n",
    "$X:\\Omega\\longrightarrow\\mathbb{R}$.\n",
    "\n",
    "The cumulative distribution function (CDF) $F_X$ of a random variable\n",
    "$X$ is defined by $F_X(x) = \\mathbb{P}(X\\leq x).$\n",
    "\n",
    "A **stochastic process** is an indexed family of random variables\n",
    "${\\{X_t\\}_{t\\in T}}$, where the indexing set $T$ is not necessarily\n",
    "countable, and the index $t$ is often interpreted as time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9f6b7",
   "metadata": {},
   "source": [
    "### 1.1.2. <a id='toc1_1_2_'></a>[Definition 1.1.2 - Continuous RVs](#toc0_)\n",
    "\n",
    "$X$ is said to be a **continuous** random variable if its law\n",
    "$\\,\\mathbb{P}_X = \\mathbb{P}\\circ X^{-1}$ is absolutely continuous with\n",
    "respect to the Lebesgue measure $\\lambda$ as a measure on $\\mathbb{R}$. That is, if\n",
    "\n",
    "$$\\forall \\, N \\in \\mathcal{B}(\\mathbb{R}):$$\n",
    "$$\\lambda(N) = 0 \\Rightarrow \\mathbb{P}(X \\in N) = 0.$$\n",
    "\n",
    "By the Radon-Nikodym theorem, a random variable $X$ is continuous if\n",
    "(and only if) there exists a measurable function\n",
    "$f_X : \\mathbb{R} \\longrightarrow [0,\\infty)$ such that for all\n",
    "$\\, B \\in \\mathcal{B}(\\mathbb{R})$,\n",
    "\n",
    "$$\\mathbb{P}(X\\in B) = \\int_B f_X\\,\\text{d}\\lambda.$$\n",
    "\n",
    "The function $f$ is called the probability density function (PDF) of $X$\n",
    "and is unique up to equality almost everywhere.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Unless otherwise stated we now assume that a random variable $X$ is\n",
    "continuous and has density $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441c276",
   "metadata": {},
   "source": [
    "### 1.1.3. <a id='toc1_1_3_'></a>[Definition 1.1.3 - Random Vectors](#toc0_)\n",
    "\n",
    "A **random vector** $\\mathbf{X}$ is an n-tuple of random\n",
    "variables\n",
    "\n",
    "$$\\mathbf{X}=(X_1,\\ldots,X_n) : \\Omega \\longrightarrow \\mathbb{R}^n.$$\n",
    "\n",
    "The joint CDF $F_{X,Y}$ of a pair of random variables $X,\\,Y$ is defined\n",
    "as\n",
    "\n",
    "$$F_{X,Y}(x,y) = \\mathbb{P}(X\\leq x, Y\\leq y).$$\n",
    "\n",
    "From the joint CDF $F_{X,Y}$ we can recover the marginal CDFs $F_X$,\n",
    "$F_Y$ by sending the other variable to infinity:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "F_X(x) &= \\lim_{y\\to\\infty}F_{X,Y}(x,y),\\\\\n",
    "\\\\\n",
    "F_Y(y) &= \\lim_{x\\to\\infty}F_{X,Y}(x,y).\n",
    "\\end{aligned}$$\n",
    "\n",
    "X and Y are **jointly continuous** if their joint law is absolutely\n",
    "continuous with respect to the two-dimensional Lebesgue measure\n",
    "$\\lambda_2$ on $(\\mathbb{R}^2,\\mathcal{B}(\\mathbb{R}^2)).$ By the\n",
    "Radon-Nikodym theorem, X and Y are jointly continuous if (and only if)\n",
    "there exists a measurable function\n",
    "$f_{X,Y} : \\mathbb{R}^2 \\longrightarrow [0,\\infty)$ such that for all\n",
    "$\\, B \\in \\mathcal{B}(\\mathbb{R}^2)$,\n",
    "\n",
    "$$\\mathbb{P}((X,Y)\\in B) = \\int_B f_{X,Y}\\,\\text{d}\\lambda_2,$$ \n",
    "\n",
    "where\n",
    "$f_{X,Y}$ is called the **joint PDF** of X and Y. The marginal PDFs\n",
    "$f_X$, $f_Y$ can be obtained from $f_{X,Y}$ by integrating out the other\n",
    "variable:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f_X(x) &= \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)\\,\\text{d} y\\\\\n",
    "\\\\\n",
    "f_Y(y) &= \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)\\,\\text{d} x.\n",
    "\\end{aligned}$$\n",
    "\n",
    "In particular, jointly continuous random variables are automatically\n",
    "marginally continuous, although the converse is not true in general.\n",
    "\n",
    "Analagously, $X_1,\\dots,X_n$ are jointly continuous if their joint\n",
    "    law is absolutely continuous with respect to n-dimensional Lebesgue measure $\\lambda_n$, or\n",
    "    equivalently if there exists a joint PDF for the random vector $(X_1,\\dots,X_n)$.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d77ec9",
   "metadata": {},
   "source": [
    "## 1.2. <a id='toc1_2_'></a>[Expectation, Moments and Independence](#toc0_)\n",
    "\n",
    "### 1.2.1. <a id='toc1_2_1_'></a>[Definition 1.2.1 - Expectation](#toc0_)\n",
    "\n",
    "The **expectation** $\\mathbb{E}[X]$ of a random variable $X$ is simply\n",
    "its Lebesgue integral with respect to $\\mathbb{P}$ \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\mathbb{E}[X] &= \\int_\\Omega X \\, \\text{d}\\mathbb{P}\\\\\n",
    "    &= \\int_\\mathbb{R} xf(x) \\,\\text{d} x.\n",
    "\\end{aligned}$$ \n",
    "\n",
    "The $k^{th}$ moment of $f$ around the non-random value\n",
    "$c\\in\\mathbb{R}$ is\n",
    "\n",
    "$$\\mathbb{E}\\left[(X-c)^k\\right] = \\int_{-\\infty}^{\\infty} (x-c)^kf(x)\\,\\text{d} x.$$\n",
    "\n",
    "The $k^{th}$ raw moment is the $k^{th}$ moment around the origin, $c=0$,\n",
    "$$\\mathbb{E}[X^k] = \\int_{-\\infty}^{\\infty} x^kf(x)\\,\\text{d} x.$$\n",
    "\n",
    "For example, the $1^{st}$ raw moment is the distribution's mean,\n",
    "$\\mu = \\mathbb{E}[X]$.\n",
    "\n",
    "The $k^{th}$ central moment is the $k^{th}$ moment around the mean,\n",
    "$c = \\mu = \\mathbb{E}[X]$,\n",
    "\n",
    "$$\\mathbb{E}[(X-\\mu)^k] = \\int_{-\\infty}^{\\infty} (x-\\mu)^kf(x)\\,\\text{d} x.$$\n",
    "\n",
    "For example, the $2^{nd}$ central moment is the distribution's variance,\n",
    "$\\sigma^2 = \\mathbb{E}\\left[(X-\\mu)^2\\right]$.\n",
    "\n",
    "By abuse of language, it is common to refer to integrals of the form\n",
    "$\\int r(x)f(x)\\,\\text{d} x$ as 'moments' even when the function $r$ is not a\n",
    "polynomial in $x$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf505790",
   "metadata": {},
   "source": [
    "### 1.2.2. <a id='toc1_2_2_'></a>[Definition 1.2.2 - Conditional Probability](#toc0_)\n",
    "\n",
    "Given continuous random variables $X$ and $Y$ with $f_Y(y)>0$ we define:\n",
    "\n",
    "1.  The conditional CDF $F_{X|Y}$ of $X$ given Y by\n",
    "\n",
    "    $$F_{X|Y}(x|y) = \\frac{\\int_{-\\infty}^{x}f_{X,Y}(u,y)\\,\\text{d} u}{f_Y(y)}.$$\n",
    "\n",
    "2.  The conditional PDF $f_{X|Y}$ of $X$ given $Y$ by\n",
    "\n",
    "    $$f_{X|Y}(x|y) = \\frac{f_{X,Y}(x,y)}{f_Y(y)}.$$\n",
    "\n",
    "3.  The conditional probability of the event $\\{ X\\in A\\}$,\n",
    "    $A\\in\\mathcal{B}(\\mathbb{R)}$, given that $Y = y$ by\n",
    "\n",
    "    $$\\mathbb{P}(X\\in A|Y = y) = \\int_A f_{X|Y}(x|y)\\,\\text{d} x.$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74746b",
   "metadata": {},
   "source": [
    "### 1.2.3. <a id='toc1_2_3_'></a>[Definition 1.2.3 - Independence of RVs](#toc0_)\n",
    "\n",
    "Random variables $X$ and $Y$ are said to be **independent** if their\n",
    "joint CDF $F_{X,Y}$ factorises into the tensor product of the\n",
    "marginals:\n",
    "\n",
    "$$F_{X,Y}(x,y) = F_X(x)F_Y(y).$$\n",
    "\n",
    "Equivalently, if X and Y are jointly continuous then we say they are\n",
    "independent if their joint PDF $f_{X,Y}$ factorises into the tensor\n",
    "product of the marginals:\n",
    "\n",
    "$$f_{X,Y}(x,y) = f_X(x)f_Y(y)\\quad\\text{a.e.}$$\n",
    "\n",
    "Where for $f,g:E\\longrightarrow \\mathbb{R}$ the **tensor product**\n",
    "    $f\\otimes g : E^2\\longrightarrow \\mathbb{R}$ is defined by\n",
    "    $f\\otimes g(x,y) = f(x)g(y).$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfbff9",
   "metadata": {},
   "source": [
    "### 1.2.4. <a id='toc1_2_4_'></a>[Remark 1.2.4](#toc0_)\n",
    "\n",
    " This is not the most compact and elegant way of defining independence of random variables through the independence of the $\\sigma$-algebras they generate. However this definition is equivalent, more intuitive and will suffice for our purposes. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[References](#toc0_)\n",
    "\n",
    "- [1.] Josephine Evans. *MA359 Measure Theory*, 2022. Warwick Mathematics Institute, University of Warwick.\n",
    "- [2.] Paul Chleboun. *ST318 Probability Theory*, 2022. Department of Statistics, University of Warwick.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
