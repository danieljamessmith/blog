{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"The Boltzmann Equation - 4. Maximum Entropy\"\n",
    "author: \"Daniel Smith\"\n",
    "date: \"2024-03-24\"\n",
    "categories: [Mathematics, Probability Theory, Information Theory, Boltzmann Equation]\n",
    "title-block-banner: false\n",
    "image: 'preview.png'\n",
    "draft: true\n",
    "description:  \"We state and prove the maximum entropy theorem following Cover, and remark on its physical interpretation.\"\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Maximum Entropy \n",
    "\n",
    "## 4.1 - Exponential Functions Maximise Entropy\n",
    "\n",
    "Consider the following problem as posed by Cover:\n",
    "\n",
    "Maximise the entropy $h(f)$ over all densities $f$ satisfying\n",
    "\n",
    "1.  $f(x)\\geq0$ with equality outside of a given set $S$.\n",
    "\n",
    "2.  $\\int_Sf(x)\\,\\text{d}x = 1$\n",
    "\n",
    "3.  $\\int_S f(x)r_i(x)\\,\\text{d}x = \\alpha_i$ for given functions $r_i$,\n",
    "    $i = 1,\\dots,m.$\n",
    "\n",
    "That is, we wish to maximise the entropy over all probability\n",
    "distributions supported on the set $S$ satisfying the $m$ given moment\n",
    "constraints $\\mathbb{E}[r_i(X)] = \\alpha_i$.\n",
    "\n",
    "Motivated by a variational calculus calculation (and our physical\n",
    "intuition) it is natural to conjecture that the solution to this\n",
    "optimization problem takes the form of an exponential function. Indeed,\n",
    "we prove this in the following theorem by using the information\n",
    "inequality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Theorem 4.1.1\n",
    "\n",
    "For $x\\in S$ define\n",
    "\n",
    "$$f^*(x) = \\exp{\\left[\\lambda_0 + \\sum_{i=0}^m \\lambda_i r_i(x)\\right]}$$\n",
    "\n",
    "where $\\lambda_0, \\lambda_1,\\dots,\\lambda_m$ are chosen such that\n",
    "\n",
    "$$\\int_Sf^*=1,\\quad\\int_Sf^*r_i=\\alpha_i.$$\n",
    "\n",
    "Then $f^*$ uniquely (up to equality almost everywhere) maximises the entropy $h(f)$ over all densities\n",
    "$f$ satisfying conditions 1, 2 and 3 as stated above.\n",
    "\n",
    "*Proof.* Let $g$ satisfy conditions 1, 2 and 3. Then: $$\\begin{aligned}\n",
    "h(g) &= -\\int g\\log g\\\\\n",
    "&= -\\int g\\log\\frac{g}{f^*}f^*\\\\\n",
    "&= -D(g\\,||\\,f^*) -\\int g\\log f^*\\\\\n",
    "&\\leq -\\int g\\log f^*\\\\\n",
    "&= -\\int g\\left(\\lambda_0 + \\sum_{i=1}^m\\lambda_ir_i\\right)\\\\\n",
    "&= -\\int f^*\\left(\\lambda_0 + \\sum_{i=1}^m\\lambda_ir_i\\right)\\\\\n",
    "&= -\\int f^* \\log f^*\\\\\n",
    "&= h(f^*)\n",
    "\\end{aligned}$$ in which we have equality iff we have equality in the\n",
    "information equality. i.e. iff $g = f^*$ a.e. â—»\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
