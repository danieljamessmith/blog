[
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import randint, uniform\n\n# Visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Model\nfrom lightgbm import LGBMClassifier"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-homeplanet-destination-and-vip",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-homeplanet-destination-and-vip",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Filling HomePlanet, Destination and VIP",
    "text": "Filling HomePlanet, Destination and VIP\n\ndf_train['HomePlanet'].value_counts()\n\nHomePlanet\nEarth     4602\nEuropa    2131\nMars      1759\nName: count, dtype: int64\n\n\n\ndf_test['HomePlanet'].value_counts()\n\nHomePlanet\nEarth     2263\nEuropa    1002\nMars       925\nName: count, dtype: int64\n\n\nThe mode for HomePlanet for both the train and test sets is “Earth”, so we use this to fill the null values\n\ndata['HomePlanet'] = data['HomePlanet'].fillna('Earth')\n\n\ndf_train['Destination'].value_counts()\n\nDestination\nTRAPPIST-1e      5915\n55 Cancri e      1800\nPSO J318.5-22     796\nName: count, dtype: int64\n\n\n\ndf_test['Destination'].value_counts()\n\nDestination\nTRAPPIST-1e      2956\n55 Cancri e       841\nPSO J318.5-22     388\nName: count, dtype: int64\n\n\nThe mode for Destination for both the train and test sets is “TRAPPIST-1e”, so we use this to fill the null values\n\ndata['Destination'] = data['Destination'].fillna('TRAPPIST-1e')\n\n\ndf_train['VIP'].value_counts()\n\nVIP\nFalse    8291\nTrue      199\nName: count, dtype: int64\n\n\n\ndf_test['VIP'].value_counts()\n\nVIP\nFalse    4110\nTrue       74\nName: count, dtype: int64\n\n\n\ndata['VIP'] = data['VIP'].fillna(False)\n\n\ndata.isna().sum()\n\nPassengerId            0\nHomePlanet             0\nCryoSleep              0\nCabin                299\nDestination            0\nAge                  270\nVIP                    0\nRoomService          170\nFoodCourt            180\nShoppingMall         175\nSpa                  177\nVRDeck               177\nName                 294\nTransported         4277\nTotalExpenditure       0\ndtype: int64"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-age-and-the-expenditure-features",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-age-and-the-expenditure-features",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Filling Age and the expenditure features",
    "text": "Filling Age and the expenditure features\nTo fill the remaining null values in Age and Expenses_features we will use the median, to reduce the influence of outliers. This requires seperating data back into constituent train and test sets, to avoid data leakage.\n\ntrain = data[:len(df_train)]\ntest = data[len(df_train):].drop('Transported', axis=1)\n\n\nprint(len(train) == len(df_train))\n\nTrue\n\n\n\ntrain.loc[:, 'Age'] = train['Age'].fillna(train['Age'].median())\ntest.loc[:, 'Age'] = test['Age'].fillna(test['Age'].median())\n\n\ntrain.loc[:,Expenses_features] = train[Expenses_features].fillna(train[Expenses_features].median())\ntest.loc[:,Expenses_features] = test[Expenses_features].fillna(test[Expenses_features].median())\n\n\nprint('Remaining null values in train:\\n')\nprint(train.isna().sum())\nprint('\\nRemaining null values in test:\\n')\nprint(test.isna().sum())\n\nRemaining null values in train:\n\nPassengerId           0\nHomePlanet            0\nCryoSleep             0\nCabin               199\nDestination           0\nAge                   0\nVIP                   0\nRoomService           0\nFoodCourt             0\nShoppingMall          0\nSpa                   0\nVRDeck                0\nName                200\nTransported           0\nTotalExpenditure      0\ndtype: int64\n\nRemaining null values in test:\n\nPassengerId           0\nHomePlanet            0\nCryoSleep             0\nCabin               100\nDestination           0\nAge                   0\nVIP                   0\nRoomService           0\nFoodCourt             0\nShoppingMall          0\nSpa                   0\nVRDeck                0\nName                 94\nTotalExpenditure      0\ndtype: int64\n\n\nRedefine data as the concatenation of train and test\n\ndata = pd.concat([train,test], axis=0)"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#new-features---agegroup-cabinside-and-groupsize",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#new-features---agegroup-cabinside-and-groupsize",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "New features - AgeGroup, CabinSide and GroupSize",
    "text": "New features - AgeGroup, CabinSide and GroupSize\nCreate a new feature AgeGroup by binning the Age feature into 8 different categories.\n\ndata['Age'].max()\n\n79.0\n\n\n\ndata['AgeGroup'] = 0\nfor i in range(8):\n    data.loc[(data.Age &gt;= 10*i) & (data.Age &lt; 10*(i + 1)), 'AgeGroup'] = i\n\n\ndata['AgeGroup'].value_counts()\n\nAgeGroup\n2    4460\n3    2538\n1    2235\n4    1570\n0     980\n5     809\n6     312\n7      66\nName: count, dtype: int64\n\n\nCreate a dummy feature Group by extracting the first character from the PassengerId column. Use Group to define a new feature GroupSize indicating how many people are in the passengers group. Drop the feature Group as it has too many values to be useful.\n\ndata['Group'] = data['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\ndata['GroupSize'] = data['Group'].map(lambda x: data['Group'].value_counts()[x])\ndata = data.drop('Group', axis=1)\n\nCreate a new boolean feature Solo, indicating if a passenger is in a group just by themselves\n\ndata['Solo'] = (data['GroupSize'] == 1).astype(int)\n\nWe won’t use Cabin directly, but we engineer a new feature CabinSide by taking the last character of Cabin. “P” for port and “S” for starboard. To implement this we fill Cabin with a placeholder value.\n\ndata['Cabin'] = data['Cabin'].fillna('T/0/P')\n\n\ndata['CabinSide'] = data['Cabin'].apply(lambda x: x.split('/')[-1])"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#finishing-preprocessing---dropping-features-and-splitting-into-train-and-test-sets",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#finishing-preprocessing---dropping-features-and-splitting-into-train-and-test-sets",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Finishing preprocessing - dropping features and splitting into train and test sets",
    "text": "Finishing preprocessing - dropping features and splitting into train and test sets\n\ndata = data.drop(['PassengerId','Cabin','Name'], axis=1)\n\n\ndata.isna().sum()\n\nHomePlanet             0\nCryoSleep              0\nDestination            0\nAge                    0\nVIP                    0\nRoomService            0\nFoodCourt              0\nShoppingMall           0\nSpa                    0\nVRDeck                 0\nTransported         4277\nTotalExpenditure       0\nAgeGroup               0\nGroupSize              0\nSolo                   0\nCabinSide              0\ndtype: int64\n\n\n\ndata\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTransported\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEuropa\nFalse\nTRAPPIST-1e\n39.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nFalse\n0.0\n3\n1\n1\nP\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n24.0\nFalse\n109.0\n9.0\n25.0\n549.0\n44.0\nTrue\n736.0\n2\n1\n1\nS\n\n\n2\nEuropa\nFalse\nTRAPPIST-1e\n58.0\nTrue\n43.0\n3576.0\n0.0\n6715.0\n49.0\nFalse\n10383.0\n5\n2\n0\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n33.0\nFalse\n0.0\n1283.0\n371.0\n3329.0\n193.0\nFalse\n5176.0\n3\n2\n0\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n16.0\nFalse\n303.0\n70.0\n151.0\n565.0\n2.0\nTrue\n1091.0\n1\n1\n1\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4272\nEarth\nTrue\nTRAPPIST-1e\n34.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n3\n2\n0\nS\n\n\n4273\nEarth\nFalse\nTRAPPIST-1e\n42.0\nFalse\n0.0\n847.0\n17.0\n10.0\n144.0\nNaN\n1018.0\n4\n1\n1\nP\n\n\n4274\nMars\nTrue\n55 Cancri e\n26.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n2\n1\n1\nP\n\n\n4275\nEuropa\nFalse\nTRAPPIST-1e\n26.0\nFalse\n0.0\n2680.0\n0.0\n0.0\n523.0\nNaN\n3203.0\n2\n1\n1\nP\n\n\n4276\nEarth\nTrue\nPSO J318.5-22\n43.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n4\n1\n1\nS\n\n\n\n\n12970 rows × 16 columns\n\n\n\n\ntrain = data[:len(df_train)]\ntest = data[len(df_train):].drop('Transported', axis=1)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTransported\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEuropa\nFalse\nTRAPPIST-1e\n39.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nFalse\n0.0\n3\n1\n1\nP\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n24.0\nFalse\n109.0\n9.0\n25.0\n549.0\n44.0\nTrue\n736.0\n2\n1\n1\nS\n\n\n2\nEuropa\nFalse\nTRAPPIST-1e\n58.0\nTrue\n43.0\n3576.0\n0.0\n6715.0\n49.0\nFalse\n10383.0\n5\n2\n0\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n33.0\nFalse\n0.0\n1283.0\n371.0\n3329.0\n193.0\nFalse\n5176.0\n3\n2\n0\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n16.0\nFalse\n303.0\n70.0\n151.0\n565.0\n2.0\nTrue\n1091.0\n1\n1\n1\nS\n\n\n\n\n\n\n\n\ntest.head()\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEarth\nTrue\nTRAPPIST-1e\n27.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2\n1\n1\nS\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n19.0\nFalse\n0.0\n9.0\n0.0\n2823.0\n0.0\n2832.0\n1\n1\n1\nS\n\n\n2\nEuropa\nTrue\n55 Cancri e\n31.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3\n1\n1\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n38.0\nFalse\n0.0\n6652.0\n0.0\n181.0\n585.0\n7418.0\n3\n1\n1\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n20.0\nFalse\n10.0\n0.0\n635.0\n0.0\n0.0\n645.0\n2\n1\n1\nS\n\n\n\n\n\n\n\nThese are our final dataframes for the train and test set. We have engineered new features TotalExpenditure, AgeGroup, GroupSize, Solo and CabinSide. We have filled all null values, and are now nearly ready to train a model"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This portfolio is made with Quarto, an open source techinical publishing system that provides functionality to render Jupyter Notebooks as blog posts. I am using GitHub Pages to host."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "The Spaceship Titanic with LightGBM\n\n\n\n\n\n\n\nLightGBM\n\n\nBinary Classification\n\n\n\n\nWe train a LightGBM classifier with hyperparameters tuned using a random search to achieve &gt;80% classification accuracy on the Spaceship Titanic dataset from Kaggle, an impressive score for a simple model.\n\n\n\n\n\n\nNov 23, 2023\n\n\nDaniel Smith\n\n\n\n\n\n\nNo matching items"
  }
]