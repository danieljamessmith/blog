[
  {
    "objectID": "posts/Test Post 1/04-Ecommerce Purchases Exercise - Solutions.html",
    "href": "posts/Test Post 1/04-Ecommerce Purchases Exercise - Solutions.html",
    "title": "Example Post 1",
    "section": "",
    "text": "Ecommerce Purchases Exercise - Solutions\nIn this Exercise you will be given some Fake Data about some purchases done through Amazon! Just go ahead and follow the directions and try your best to answer the questions and complete the tasks. Feel free to reference the solutions. Most of the tasks can be solved in different ways. For the most part, the questions get progressively harder.\nPlease excuse anything that doesn’t make “Real-World” sense in the dataframe, all the data is fake and made-up.\nAlso note that all of these questions can be answered with one line of code. ____ ** Import pandas and read in the Ecommerce Purchases csv file and set it to a DataFrame called ecom. **\n\nimport pandas as pd\n\n\necom = pd.read_csv('Ecommerce Purchases')\n\nCheck the head of the DataFrame.\n\necom.head()\n\n\n\n\n\n\n\nAddress\nLot\nAM or PM\nBrowser Info\nCompany\nCredit Card\nCC Exp Date\nCC Security Code\nCC Provider\nEmail\nJob\nIP Address\nLanguage\nPurchase Price\n\n\n\n\n0\n16629 Pace Camp Apt. 448\\nAlexisborough, NE 77...\n46 in\nPM\nOpera/9.56.(X11; Linux x86_64; sl-SI) Presto/2...\nMartinez-Herman\n6011929061123406\n02/20\n900\nJCB 16 digit\npdunlap@yahoo.com\nScientist, product/process development\n149.146.147.205\nel\n98.14\n\n\n1\n9374 Jasmine Spurs Suite 508\\nSouth John, TN 8...\n28 rn\nPM\nOpera/8.93.(Windows 98; Win 9x 4.90; en-US) Pr...\nFletcher, Richards and Whitaker\n3337758169645356\n11/18\n561\nMastercard\nanthony41@reed.com\nDrilling engineer\n15.160.41.51\nfr\n70.73\n\n\n2\nUnit 0065 Box 5052\\nDPO AP 27450\n94 vE\nPM\nMozilla/5.0 (compatible; MSIE 9.0; Windows NT ...\nSimpson, Williams and Pham\n675957666125\n08/19\n699\nJCB 16 digit\namymiller@morales-harrison.com\nCustomer service manager\n132.207.160.22\nde\n0.95\n\n\n3\n7780 Julia Fords\\nNew Stacy, WA 45798\n36 vm\nPM\nMozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0 ...\nWilliams, Marshall and Buchanan\n6011578504430710\n02/24\n384\nDiscover\nbrent16@olson-robinson.info\nDrilling engineer\n30.250.74.19\nes\n78.04\n\n\n4\n23012 Munoz Drive Suite 337\\nNew Cynthia, TX 5...\n20 IE\nAM\nOpera/9.58.(X11; Linux x86_64; it-IT) Presto/2...\nBrown, Watson and Andrews\n6011456623207998\n10/25\n678\nDiners Club / Carte Blanche\nchristopherwright@gmail.com\nFine artist\n24.140.33.94\nes\n77.82\n\n\n\n\n\n\n\n** How many rows and columns are there? **\n\necom.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 14 columns):\nAddress             10000 non-null object\nLot                 10000 non-null object\nAM or PM            10000 non-null object\nBrowser Info        10000 non-null object\nCompany             10000 non-null object\nCredit Card         10000 non-null int64\nCC Exp Date         10000 non-null object\nCC Security Code    10000 non-null int64\nCC Provider         10000 non-null object\nEmail               10000 non-null object\nJob                 10000 non-null object\nIP Address          10000 non-null object\nLanguage            10000 non-null object\nPurchase Price      10000 non-null float64\ndtypes: float64(1), int64(2), object(11)\nmemory usage: 1.1+ MB\n\n\n** What is the average Purchase Price? **\n\necom['Purchase Price'].mean()\n\n50.34730200000025\n\n\n** What were the highest and lowest purchase prices? **\n\necom['Purchase Price'].max()\n\n99.989999999999995\n\n\n\necom['Purchase Price'].min()\n\n0.0\n\n\n** How many people have English ‘en’ as their Language of choice on the website? **\n\necom[ecom['Language']=='en'].count()\n\nAddress             1098\nLot                 1098\nAM or PM            1098\nBrowser Info        1098\nCompany             1098\nCredit Card         1098\nCC Exp Date         1098\nCC Security Code    1098\nCC Provider         1098\nEmail               1098\nJob                 1098\nIP Address          1098\nLanguage            1098\nPurchase Price      1098\ndtype: int64\n\n\n** How many people have the job title of “Lawyer” ? **\n\necom[ecom['Job'] == 'Lawyer'].info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 30 entries, 470 to 9979\nData columns (total 14 columns):\nAddress             30 non-null object\nLot                 30 non-null object\nAM or PM            30 non-null object\nBrowser Info        30 non-null object\nCompany             30 non-null object\nCredit Card         30 non-null int64\nCC Exp Date         30 non-null object\nCC Security Code    30 non-null int64\nCC Provider         30 non-null object\nEmail               30 non-null object\nJob                 30 non-null object\nIP Address          30 non-null object\nLanguage            30 non-null object\nPurchase Price      30 non-null float64\ndtypes: float64(1), int64(2), object(11)\nmemory usage: 3.5+ KB\n\n\n** How many people made the purchase during the AM and how many people made the purchase during PM ? **\n(Hint: Check out value_counts() ) \n\necom['AM or PM'].value_counts()\n\nPM    5068\nAM    4932\nName: AM or PM, dtype: int64\n\n\n** What are the 5 most common Job Titles? **\n\necom['Job'].value_counts().head(5)\n\nInterior and spatial designer    31\nLawyer                           30\nSocial researcher                28\nPurchasing manager               27\nDesigner, jewellery              27\nName: Job, dtype: int64\n\n\n** Someone made a purchase that came from Lot: “90 WT” , what was the Purchase Price for this transaction? **\n\necom[ecom['Lot']=='90 WT']['Purchase Price']\n\n513    75.1\nName: Purchase Price, dtype: float64\n\n\n** What is the email of the person with the following Credit Card Number: 4926535242672853 **\n\necom[ecom[\"Credit Card\"] == 4926535242672853]['Email'] \n\n1234    bondellen@williams-garza.com\nName: Email, dtype: object\n\n\n** How many people have American Express as their Credit Card Provider and made a purchase above $95 ?**\n\necom[(ecom['CC Provider']=='American Express') & (ecom['Purchase Price']&gt;95)].count()\n\nAddress             39\nLot                 39\nAM or PM            39\nBrowser Info        39\nCompany             39\nCredit Card         39\nCC Exp Date         39\nCC Security Code    39\nCC Provider         39\nEmail               39\nJob                 39\nIP Address          39\nLanguage            39\nPurchase Price      39\ndtype: int64\n\n\n** Hard: How many people have a credit card that expires in 2025? **\n\nsum(ecom['CC Exp Date'].apply(lambda x: x[3:]) == '25')\n\n1033\n\n\n** Hard: What are the top 5 most popular email providers/hosts (e.g. gmail.com, yahoo.com, etc…) **\n\necom['Email'].apply(lambda x: x.split('@')[1]).value_counts().head(5)\n\nhotmail.com     1638\nyahoo.com       1616\ngmail.com       1605\nsmith.com         42\nwilliams.com      37\nName: Email, dtype: int64\n\n\n\n\nGreat Job!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The blog is made with Quarto, an open source techinical publishing system supporting Jupyter Notebooks. I am using GitHub Pages to host."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "The Spaceship Titanic with LightGBM\n\n\n\n\n\n\n\nLightGBM\n\n\nBinary Classification\n\n\n\n\nWe train a LightGBM classifier with hyperparameters tuned using a random search to achieve &gt;80% classification accuracy on the Spaceship Titanic dataset from Kaggle, an impressive score for a simple model.\n\n\n\n\n\n\nNov 23, 2023\n\n\nDaniel Smith\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import randint, uniform\n\n# Visulisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Model\nfrom lightgbm import LGBMClassifier"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-homeplanet-destination-and-vip",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-homeplanet-destination-and-vip",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Filling HomePlanet, Destination and VIP",
    "text": "Filling HomePlanet, Destination and VIP\n\ndf_train['HomePlanet'].value_counts()\n\nHomePlanet\nEarth     4602\nEuropa    2131\nMars      1759\nName: count, dtype: int64\n\n\n\ndf_test['HomePlanet'].value_counts()\n\nHomePlanet\nEarth     2263\nEuropa    1002\nMars       925\nName: count, dtype: int64\n\n\nThe mode for HomePlanet for both the train and test sets is “Earth”, so we use this to fill the null values\n\ndata['HomePlanet'] = data['HomePlanet'].fillna('Earth')\n\n\ndf_train['Destination'].value_counts()\n\nDestination\nTRAPPIST-1e      5915\n55 Cancri e      1800\nPSO J318.5-22     796\nName: count, dtype: int64\n\n\n\ndf_test['Destination'].value_counts()\n\nDestination\nTRAPPIST-1e      2956\n55 Cancri e       841\nPSO J318.5-22     388\nName: count, dtype: int64\n\n\nThe mode for Destination for both the train and test sets is “TRAPPIST-1e”, so we use this to fill the null values\n\ndata['Destination'] = data['Destination'].fillna('TRAPPIST-1e')\n\n\ndf_train['VIP'].value_counts()\n\nVIP\nFalse    8291\nTrue      199\nName: count, dtype: int64\n\n\n\ndf_test['VIP'].value_counts()\n\nVIP\nFalse    4110\nTrue       74\nName: count, dtype: int64\n\n\n\ndata['VIP'] = data['VIP'].fillna(False)\n\n\ndata.isna().sum()\n\nPassengerId            0\nHomePlanet             0\nCryoSleep              0\nCabin                299\nDestination            0\nAge                  270\nVIP                    0\nRoomService          170\nFoodCourt            180\nShoppingMall         175\nSpa                  177\nVRDeck               177\nName                 294\nTransported         4277\nTotalExpenditure       0\ndtype: int64"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-age-and-the-expenditure-features",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#filling-age-and-the-expenditure-features",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Filling Age and the expenditure features",
    "text": "Filling Age and the expenditure features\nTo fill the remaining null values in Age and Expenses_features we will use the median, to reduce the influence of outliers. This requires seperating data back into constituent train and test sets, to avoid data leakage.\n\ntrain = data[:len(df_train)]\ntest = data[len(df_train):].drop('Transported', axis=1)\n\n\nprint(len(train) == len(df_train))\n\nTrue\n\n\n\ntrain.loc[:, 'Age'] = train['Age'].fillna(train['Age'].median())\ntest.loc[:, 'Age'] = test['Age'].fillna(test['Age'].median())\n\n\ntrain.loc[:,Expenses_features] = train[Expenses_features].fillna(train[Expenses_features].median())\ntest.loc[:,Expenses_features] = test[Expenses_features].fillna(test[Expenses_features].median())\n\n\nprint('Remaining null values in train:\\n')\nprint(train.isna().sum())\nprint('\\nRemaining null values in test:\\n')\nprint(test.isna().sum())\n\nRemaining null values in train:\n\nPassengerId           0\nHomePlanet            0\nCryoSleep             0\nCabin               199\nDestination           0\nAge                   0\nVIP                   0\nRoomService           0\nFoodCourt             0\nShoppingMall          0\nSpa                   0\nVRDeck                0\nName                200\nTransported           0\nTotalExpenditure      0\ndtype: int64\n\nRemaining null values in test:\n\nPassengerId           0\nHomePlanet            0\nCryoSleep             0\nCabin               100\nDestination           0\nAge                   0\nVIP                   0\nRoomService           0\nFoodCourt             0\nShoppingMall          0\nSpa                   0\nVRDeck                0\nName                 94\nTotalExpenditure      0\ndtype: int64\n\n\nRedefine data as the concatenation of train and test\n\ndata = pd.concat([train,test], axis=0)"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#new-features---agegroup-cabinside-and-groupsize",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#new-features---agegroup-cabinside-and-groupsize",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "New features - AgeGroup, CabinSide and GroupSize",
    "text": "New features - AgeGroup, CabinSide and GroupSize\nCreate a new feature AgeGroup by binning the Age feature into 8 different categories.\n\ndata['Age'].max()\n\n79.0\n\n\n\ndata['AgeGroup'] = 0\nfor i in range(8):\n    data.loc[(data.Age &gt;= 10*i) & (data.Age &lt; 10*(i + 1)), 'AgeGroup'] = i\n\n\ndata['AgeGroup'].value_counts()\n\nAgeGroup\n2    4460\n3    2538\n1    2235\n4    1570\n0     980\n5     809\n6     312\n7      66\nName: count, dtype: int64\n\n\nCreate a dummy feature Group by extracting the first character from the PassengerId column. Use Group to define a new feature GroupSize indicating how many people are in the passengers group. Drop the feature Group as it has too many values to be useful.\n\ndata['Group'] = data['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\ndata['GroupSize'] = data['Group'].map(lambda x: data['Group'].value_counts()[x])\ndata = data.drop('Group', axis=1)\n\nCreate a new boolean feature Solo, indicating if a passenger is in a group just by themselves\n\ndata['Solo'] = (data['GroupSize'] == 1).astype(int)\n\nWe won’t use Cabin directly, but we engineer a new feature CabinSide by taking the first character of Cabin. “P” for port and “S” for starboard. To implement this we fill Cabin with a placeholder value.\n\ndata['Cabin'] = data['Cabin'].fillna('T/0/P')\n\n\ndata['CabinSide'] = data['Cabin'].apply(lambda x: x.split('/')[-1])"
  },
  {
    "objectID": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#finishing-preprocessing---dropping-features-and-splitting-into-train-and-test-sets",
    "href": "posts/Spaceship Titanic/The Spaceship Titanic with LightGBM.html#finishing-preprocessing---dropping-features-and-splitting-into-train-and-test-sets",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Finishing preprocessing - dropping features and splitting into train and test sets",
    "text": "Finishing preprocessing - dropping features and splitting into train and test sets\n\ndata = data.drop(['PassengerId','Cabin','Name'], axis=1)\n\n\ndata.isna().sum()\n\nHomePlanet             0\nCryoSleep              0\nDestination            0\nAge                    0\nVIP                    0\nRoomService            0\nFoodCourt              0\nShoppingMall           0\nSpa                    0\nVRDeck                 0\nTransported         4277\nTotalExpenditure       0\nAgeGroup               0\nGroupSize              0\nSolo                   0\nCabinSide              0\ndtype: int64\n\n\n\ndata\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTransported\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEuropa\nFalse\nTRAPPIST-1e\n39.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nFalse\n0.0\n3\n1\n1\nP\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n24.0\nFalse\n109.0\n9.0\n25.0\n549.0\n44.0\nTrue\n736.0\n2\n1\n1\nS\n\n\n2\nEuropa\nFalse\nTRAPPIST-1e\n58.0\nTrue\n43.0\n3576.0\n0.0\n6715.0\n49.0\nFalse\n10383.0\n5\n2\n0\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n33.0\nFalse\n0.0\n1283.0\n371.0\n3329.0\n193.0\nFalse\n5176.0\n3\n2\n0\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n16.0\nFalse\n303.0\n70.0\n151.0\n565.0\n2.0\nTrue\n1091.0\n1\n1\n1\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4272\nEarth\nTrue\nTRAPPIST-1e\n34.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n3\n2\n0\nS\n\n\n4273\nEarth\nFalse\nTRAPPIST-1e\n42.0\nFalse\n0.0\n847.0\n17.0\n10.0\n144.0\nNaN\n1018.0\n4\n1\n1\nP\n\n\n4274\nMars\nTrue\n55 Cancri e\n26.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n2\n1\n1\nP\n\n\n4275\nEuropa\nFalse\nTRAPPIST-1e\n26.0\nFalse\n0.0\n2680.0\n0.0\n0.0\n523.0\nNaN\n3203.0\n2\n1\n1\nP\n\n\n4276\nEarth\nTrue\nPSO J318.5-22\n43.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n4\n1\n1\nS\n\n\n\n\n12970 rows × 16 columns\n\n\n\n\ntrain = data[:len(df_train)]\ntest = data[len(df_train):].drop('Transported', axis=1)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTransported\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEuropa\nFalse\nTRAPPIST-1e\n39.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nFalse\n0.0\n3\n1\n1\nP\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n24.0\nFalse\n109.0\n9.0\n25.0\n549.0\n44.0\nTrue\n736.0\n2\n1\n1\nS\n\n\n2\nEuropa\nFalse\nTRAPPIST-1e\n58.0\nTrue\n43.0\n3576.0\n0.0\n6715.0\n49.0\nFalse\n10383.0\n5\n2\n0\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n33.0\nFalse\n0.0\n1283.0\n371.0\n3329.0\n193.0\nFalse\n5176.0\n3\n2\n0\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n16.0\nFalse\n303.0\n70.0\n151.0\n565.0\n2.0\nTrue\n1091.0\n1\n1\n1\nS\n\n\n\n\n\n\n\n\ntest.head()\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEarth\nTrue\nTRAPPIST-1e\n27.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2\n1\n1\nS\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n19.0\nFalse\n0.0\n9.0\n0.0\n2823.0\n0.0\n2832.0\n1\n1\n1\nS\n\n\n2\nEuropa\nTrue\n55 Cancri e\n31.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3\n1\n1\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n38.0\nFalse\n0.0\n6652.0\n0.0\n181.0\n585.0\n7418.0\n3\n1\n1\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n20.0\nFalse\n10.0\n0.0\n635.0\n0.0\n0.0\n645.0\n2\n1\n1\nS\n\n\n\n\n\n\n\nThese are our final dataframes for the train and test set. We have engineered new features TotalExpenditure, AgeGroup, GroupSize, Solo and CabinSide. We have filled all null values, and are now nearly ready to train a model"
  },
  {
    "objectID": "posts/The Spaceship Titanic with LightGBM.html",
    "href": "posts/The Spaceship Titanic with LightGBM.html",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import randint, uniform\n\n# Visulisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Model\nfrom lightgbm import LGBMClassifier"
  },
  {
    "objectID": "posts/The Spaceship Titanic with LightGBM.html#filling-homeplanet-destination-and-vip",
    "href": "posts/The Spaceship Titanic with LightGBM.html#filling-homeplanet-destination-and-vip",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Filling HomePlanet, Destination and VIP",
    "text": "Filling HomePlanet, Destination and VIP\n\ndf_train['HomePlanet'].value_counts()\n\nHomePlanet\nEarth     4602\nEuropa    2131\nMars      1759\nName: count, dtype: int64\n\n\n\ndf_test['HomePlanet'].value_counts()\n\nHomePlanet\nEarth     2263\nEuropa    1002\nMars       925\nName: count, dtype: int64\n\n\nThe mode for HomePlanet for both the train and test sets is “Earth”, so we use this to fill the null values\n\ndata['HomePlanet'] = data['HomePlanet'].fillna('Earth')\n\n\ndf_train['Destination'].value_counts()\n\nDestination\nTRAPPIST-1e      5915\n55 Cancri e      1800\nPSO J318.5-22     796\nName: count, dtype: int64\n\n\n\ndf_test['Destination'].value_counts()\n\nDestination\nTRAPPIST-1e      2956\n55 Cancri e       841\nPSO J318.5-22     388\nName: count, dtype: int64\n\n\nThe mode for Destination for both the train and test sets is “TRAPPIST-1e”, so we use this to fill the null values\n\ndata['Destination'] = data['Destination'].fillna('TRAPPIST-1e')\n\n\ndf_train['VIP'].value_counts()\n\nVIP\nFalse    8291\nTrue      199\nName: count, dtype: int64\n\n\n\ndf_test['VIP'].value_counts()\n\nVIP\nFalse    4110\nTrue       74\nName: count, dtype: int64\n\n\n\ndata['VIP'] = data['VIP'].fillna(False)\n\n\ndata.isna().sum()\n\nPassengerId            0\nHomePlanet             0\nCryoSleep              0\nCabin                299\nDestination            0\nAge                  270\nVIP                    0\nRoomService          170\nFoodCourt            180\nShoppingMall         175\nSpa                  177\nVRDeck               177\nName                 294\nTransported         4277\nTotalExpenditure       0\ndtype: int64"
  },
  {
    "objectID": "posts/The Spaceship Titanic with LightGBM.html#filling-age-and-the-expenditure-features",
    "href": "posts/The Spaceship Titanic with LightGBM.html#filling-age-and-the-expenditure-features",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Filling Age and the expenditure features",
    "text": "Filling Age and the expenditure features\nTo fill the remaining null values in Age and Expenses_features we will use the median, to reduce the influence of outliers. This requires seperating data back into constituent train and test sets, to avoid data leakage.\n\ntrain = data[:len(df_train)]\ntest = data[len(df_train):].drop('Transported', axis=1)\n\n\nprint(len(train) == len(df_train))\n\nTrue\n\n\n\ntrain.loc[:, 'Age'] = train['Age'].fillna(train['Age'].median())\ntest.loc[:, 'Age'] = test['Age'].fillna(test['Age'].median())\n\n\ntrain.loc[:,Expenses_features] = train[Expenses_features].fillna(train[Expenses_features].median())\ntest.loc[:,Expenses_features] = test[Expenses_features].fillna(test[Expenses_features].median())\n\n\nprint('Remaining null values in train:\\n')\nprint(train.isna().sum())\nprint('\\nRemaining null values in test:\\n')\nprint(test.isna().sum())\n\nRemaining null values in train:\n\nPassengerId           0\nHomePlanet            0\nCryoSleep             0\nCabin               199\nDestination           0\nAge                   0\nVIP                   0\nRoomService           0\nFoodCourt             0\nShoppingMall          0\nSpa                   0\nVRDeck                0\nName                200\nTransported           0\nTotalExpenditure      0\ndtype: int64\n\nRemaining null values in test:\n\nPassengerId           0\nHomePlanet            0\nCryoSleep             0\nCabin               100\nDestination           0\nAge                   0\nVIP                   0\nRoomService           0\nFoodCourt             0\nShoppingMall          0\nSpa                   0\nVRDeck                0\nName                 94\nTotalExpenditure      0\ndtype: int64\n\n\nRedefine data as the concatenation of train and test\n\ndata = pd.concat([train,test], axis=0)"
  },
  {
    "objectID": "posts/The Spaceship Titanic with LightGBM.html#new-features---agegroup-cabinside-and-groupsize",
    "href": "posts/The Spaceship Titanic with LightGBM.html#new-features---agegroup-cabinside-and-groupsize",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "New features - AgeGroup, CabinSide and GroupSize",
    "text": "New features - AgeGroup, CabinSide and GroupSize\nCreate a new feature AgeGroup by binning the Age feature into 8 different categories.\n\ndata['Age'].max()\n\n79.0\n\n\n\ndata['AgeGroup'] = 0\nfor i in range(8):\n    data.loc[(data.Age &gt;= 10*i) & (data.Age &lt; 10*(i + 1)), 'AgeGroup'] = i\n\n\ndata['AgeGroup'].value_counts()\n\nAgeGroup\n2    4460\n3    2538\n1    2235\n4    1570\n0     980\n5     809\n6     312\n7      66\nName: count, dtype: int64\n\n\nCreate a dummy feature Group by extracting the first character from the PassengerId column. Use Group to define a new feature GroupSize indicating how many people are in the passengers group. Drop the feature Group as it has too many values to be useful.\n\ndata['Group'] = data['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\ndata['GroupSize'] = data['Group'].map(lambda x: data['Group'].value_counts()[x])\ndata = data.drop('Group', axis=1)\n\nCreate a new boolean feature Solo, indicating if a passenger is in a group just by themselves\n\ndata['Solo'] = (data['GroupSize'] == 1).astype(int)\n\nWe won’t use Cabin directly, but we engineer a new feature CabinSide by taking the first character of Cabin. “P” for port and “S” for starboard. To implement this we fill Cabin with a placeholder value.\n\ndata['Cabin'] = data['Cabin'].fillna('T/0/P')\n\n\ndata['CabinSide'] = data['Cabin'].apply(lambda x: x.split('/')[-1])"
  },
  {
    "objectID": "posts/The Spaceship Titanic with LightGBM.html#finishing-preprocessing---dropping-features-and-splitting-into-train-and-test-sets",
    "href": "posts/The Spaceship Titanic with LightGBM.html#finishing-preprocessing---dropping-features-and-splitting-into-train-and-test-sets",
    "title": "The Spaceship Titanic with LightGBM",
    "section": "Finishing preprocessing - dropping features and splitting into train and test sets",
    "text": "Finishing preprocessing - dropping features and splitting into train and test sets\n\ndata = data.drop(['PassengerId','Cabin','Name'], axis=1)\n\n\ndata.isna().sum()\n\nHomePlanet             0\nCryoSleep              0\nDestination            0\nAge                    0\nVIP                    0\nRoomService            0\nFoodCourt              0\nShoppingMall           0\nSpa                    0\nVRDeck                 0\nTransported         4277\nTotalExpenditure       0\nAgeGroup               0\nGroupSize              0\nSolo                   0\nCabinSide              0\ndtype: int64\n\n\n\ndata\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTransported\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEuropa\nFalse\nTRAPPIST-1e\n39.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nFalse\n0.0\n3\n1\n1\nP\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n24.0\nFalse\n109.0\n9.0\n25.0\n549.0\n44.0\nTrue\n736.0\n2\n1\n1\nS\n\n\n2\nEuropa\nFalse\nTRAPPIST-1e\n58.0\nTrue\n43.0\n3576.0\n0.0\n6715.0\n49.0\nFalse\n10383.0\n5\n2\n0\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n33.0\nFalse\n0.0\n1283.0\n371.0\n3329.0\n193.0\nFalse\n5176.0\n3\n2\n0\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n16.0\nFalse\n303.0\n70.0\n151.0\n565.0\n2.0\nTrue\n1091.0\n1\n1\n1\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4272\nEarth\nTrue\nTRAPPIST-1e\n34.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n3\n2\n0\nS\n\n\n4273\nEarth\nFalse\nTRAPPIST-1e\n42.0\nFalse\n0.0\n847.0\n17.0\n10.0\n144.0\nNaN\n1018.0\n4\n1\n1\nP\n\n\n4274\nMars\nTrue\n55 Cancri e\n26.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n2\n1\n1\nP\n\n\n4275\nEuropa\nFalse\nTRAPPIST-1e\n26.0\nFalse\n0.0\n2680.0\n0.0\n0.0\n523.0\nNaN\n3203.0\n2\n1\n1\nP\n\n\n4276\nEarth\nTrue\nPSO J318.5-22\n43.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nNaN\n0.0\n4\n1\n1\nS\n\n\n\n\n12970 rows × 16 columns\n\n\n\n\ntrain = data[:len(df_train)]\ntest = data[len(df_train):].drop('Transported', axis=1)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTransported\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEuropa\nFalse\nTRAPPIST-1e\n39.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\nFalse\n0.0\n3\n1\n1\nP\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n24.0\nFalse\n109.0\n9.0\n25.0\n549.0\n44.0\nTrue\n736.0\n2\n1\n1\nS\n\n\n2\nEuropa\nFalse\nTRAPPIST-1e\n58.0\nTrue\n43.0\n3576.0\n0.0\n6715.0\n49.0\nFalse\n10383.0\n5\n2\n0\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n33.0\nFalse\n0.0\n1283.0\n371.0\n3329.0\n193.0\nFalse\n5176.0\n3\n2\n0\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n16.0\nFalse\n303.0\n70.0\n151.0\n565.0\n2.0\nTrue\n1091.0\n1\n1\n1\nS\n\n\n\n\n\n\n\n\ntest.head()\n\n\n\n\n\n\n\n\nHomePlanet\nCryoSleep\nDestination\nAge\nVIP\nRoomService\nFoodCourt\nShoppingMall\nSpa\nVRDeck\nTotalExpenditure\nAgeGroup\nGroupSize\nSolo\nCabinSide\n\n\n\n\n0\nEarth\nTrue\nTRAPPIST-1e\n27.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2\n1\n1\nS\n\n\n1\nEarth\nFalse\nTRAPPIST-1e\n19.0\nFalse\n0.0\n9.0\n0.0\n2823.0\n0.0\n2832.0\n1\n1\n1\nS\n\n\n2\nEuropa\nTrue\n55 Cancri e\n31.0\nFalse\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3\n1\n1\nS\n\n\n3\nEuropa\nFalse\nTRAPPIST-1e\n38.0\nFalse\n0.0\n6652.0\n0.0\n181.0\n585.0\n7418.0\n3\n1\n1\nS\n\n\n4\nEarth\nFalse\nTRAPPIST-1e\n20.0\nFalse\n10.0\n0.0\n635.0\n0.0\n0.0\n645.0\n2\n1\n1\nS\n\n\n\n\n\n\n\nThese are our final dataframes for the train and test set. We have engineered new features TotalExpenditure, AgeGroup, GroupSize, Solo and CabinSide. We have filled all null values, and are now nearly ready to train a model"
  }
]